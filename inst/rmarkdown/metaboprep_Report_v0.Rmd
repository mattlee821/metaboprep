---
title: "`metaboprep` data preparation summary report"
date: "`r format(Sys.time(), '%d %B, %Y')`"
author: "Project = `r VAR_project`; Platform = `r VAR_platform`"
editor_options: 
  chunk_output_type: console
---

This report provides descriptive information for raw and filtered data for the project `r VAR_project`. An overview of the workflow can be found on <a href="https://github.com/MRCIEU/metaboprep?tab=readme-ov-file#data-preparation-steps-in-brief" target="_blank">GitHub</a>. `metaboprep` was published in 2022 in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8963298/" target="_blank">Bioinformatics</a> and updates can be found on <a href="https://github.com/MRCIEU/metaboprep/" target="_blank">GitHub</a>. The `metaboprep` package performs three operations: 

1. Provides an assessment and summary statistics of the raw data
2. Performs data filtering
3. Provides an assessment and summary statistics of the filtered data, particularly in the context of batch variables when available.

```{r init, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, quote=F, comment=NA, warning=FALSE, message=FALSE, error=FALSE, fig.align="center", fig.width =12, fig.height=6)

## test for necessary packages
if (!requireNamespace("metaboprep", quietly = TRUE)) {
    stop("Package \"metaboprep\" needed for this function to work. Please install it.",
      call. = FALSE)
}

if (!requireNamespace("dendextend", quietly = TRUE)) {
    stop("Package \"dendextend\" needed for this function to work. Please install it.",
      call. = FALSE)
}


if (!requireNamespace("tidyverse", quietly = TRUE)) {
    stop("Package \"tidyverse\" needed for this function to work. Please install it.",
      call. = FALSE)
}

if (!requireNamespace("markdown", quietly = TRUE)) {
    stop("Package \"markdown\" needed for this function to work. Please install it.",
      call. = FALSE)
}

suppressPackageStartupMessages(library(metaboprep))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(dendextend))
suppressPackageStartupMessages(library(markdown))
suppressPackageStartupMessages(library(reshape))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(RColorBrewer))
suppressPackageStartupMessages(library(cowplot))
suppressPackageStartupMessages(library(gtsummary))
```

```{r data}
## RAW DATA
raw_data$metabolite_data = tibble::as_tibble(raw_data$metabolite_data)
raw_data$sample_data = tibble::as_tibble(raw_data$sample_data); colnames(raw_data$sample_data)[1] = "SamID"
raw_data$feature_data = tibble::as_tibble(raw_data$feature_data); colnames(raw_data$feature_data)[1] = "FeatureID"
raw_data$varexp = raw_data$varexp[,1]

## QC Data
qc_data$metabolite_data = tibble::as_tibble(qc_data$metabolite_data)
qc_data$sample_data = tibble::as_tibble(qc_data$sample_data); colnames(qc_data$sample_data)[1] = "SamID"
qc_data$feature_data = tibble::as_tibble(qc_data$feature_data); colnames(qc_data$feature_data)[1] = "FeatureID"
qc_data$varexp = qc_data$varexp[,1]
```

# 1. Summary: raw data
```{r table-raw-samplesize, fig.height=2}
tout = data.frame("data.set" = c("number of samples","number of features"),  
                  "raw.data" = dim(raw_data$metabolite_data))
                  # "filtered.data" = dim(qc_data$metabolite_data))
ggpubr::ggtexttable(tout, rows = NULL, theme = ggpubr::ttheme("mBlue"))
```

## Missingness
```{r plot-raw-missingness, fig.width = 8, fig.height = 6, fig.cap=" Figure A: Distribution of sample missingness with sample mean illustrated by the red vertical line; Figure B: Distribution of feature missingness with sample mean illustrated by the red vertical line; Figure C: Table of sample and feature missingness percentiles (i.e., a table of Figure A B); Figure D: Estimates of study samples sizes under various levels of feature missingness."}
r_mis = missingness.sum(mydata = raw_data$metabolite_data)
ggpubr::ggarrange(r_mis[[4]][[1]],
                  r_mis[[4]][[2]], 
                  r_mis[[4]][[3]],
                  r_mis[[4]][[4]],
                  ncol = 2, nrow = 2,
                  labels = c("a", "b", "c", "d") )
```

# 2. Data filtering 

Six primary data filtering exclusion steps were made during the preparation of the data: 

1. `r rownames(qcing_data$exclusion_data)[1]`: sample exclusions based on >= 80% missingness were excluded
2. `r rownames(qcing_data$exclusion_data)[2]`: feature exclusions based on >= 80% missingness (xenobiotics are not included in this step)
3. `r rownames(qcing_data$exclusion_data)[3]`: sample exclusions based on >= `r VAR_sample_missingness * 100`% missingess
4. `r rownames(qcing_data$exclusion_data)[4]`: feature exclusions based on >= `r VAR_feature_missingness * 100`% missingness (xenobiotics are not included in this step)
5. `r rownames(qcing_data$exclusion_data)[5]`: sample exclusions based on total-peak-area >= `r VAR_total_peak_area_SD * 100`%  SD from the mean
6. `r rownames(qcing_data$exclusion_data)[6]`: sample exclusions based on mean >= `r `VAR_PC_outlier_SD` SD for PC1 vs. PC2 axis

```{r table-filtering-exclusions, fig.height=2}
temp = data.frame(exclusions = rownames(qcing_data$exclusion_data), count = qcing_data$exclusion_data[,1])
ggpubr::ggtexttable(temp, rows = NULL, theme = ggpubr::ttheme("mBlue"))
```

Data reduction was carried out to identify a list of representative features for generating a sample principal component analysis. This step reduces the level of inter-correlation in the data to ensure that the principal components are not driven by groups of correlated features.

```{r plot-filtering-PCs, fig.cap="Data reduction table (left) gives the number of features at each phase of the data reduction (Spearman's correlation distance tree cutting) analysis. PC plot (right) shows PC1 and PC2 for all individuals, using the representitve features identified in the data reduction analysis. The red vertical and horizontal lines indicate the standard deviation (SD) cutoffs for identifying sample outliers."}
feature_count = length(qcing_data$feature_sumstats$k)
features_included_in_data_reduction = length( na.omit(qcing_data$feature_sumstats$k) )
cluster_count = length(unique( na.omit(qcing_data$feature_sumstats$k) ) )
number_of_rep_meatbolites = sum( qcing_data$feature_sumstats$independent_features_binary == 1 )

temp = data.frame( data.reduction = c("feature count",
                                      "features included in data reduction",
                                      "number of features clusters",
                                      "number of representative features"),
                   count = c(feature_count, 
                             features_included_in_data_reduction, 
                             cluster_count, 
                             number_of_rep_meatbolites  ) )

ptable = ggpubr::ggtexttable( temp, rows = NULL, theme = ggpubr::ttheme("mBlue"))

#################
## PCA
#################
## define tibble
pcs = as_tibble(qcing_data$pcs)
## define color scheme
pcol = RColorBrewer::brewer.pal(9, "Set1")
## define accelerationfactor
accelerationfactor = qcing_data$accelerationfactor
if(accelerationfactor > 10){accelerationfactor = 10}
if(accelerationfactor == 1){accelerationfactor = 2}
## define outliers
Omat = outlier.matrix( pcs[, 1:accelerationfactor], nsd = VAR_PC_outlier_SD, meansd = TRUE )
outliers = apply(Omat, 1, sum)
outliers[outliers>0]=1
pcs$outliers = as.factor( outliers )
##
cutoffs = apply(pcs[, 1:accelerationfactor], 2, function(x){
  msd = c(mean(x, na.rm = TRUE), sd(x, na.rm = TRUE))
  cutoff = msd[1] + (msd[2]*VAR_PC_outlier_SD)
  return(cutoff)
} )
  
##
pcplot = pcs %>% ggplot( aes(x = PC1, y = PC2) ) +
  geom_point( aes(fill = outliers), size = 2.5, shape = 21 ) +
  scale_fill_manual(values = pcol[c(2,1)]) +
  geom_vline(xintercept = c(cutoffs[1], -cutoffs[1]), color = pcol[1] ) +
  geom_hline(yintercept = c(cutoffs[2], -cutoffs[2]), color = pcol[1] ) +
  theme(legend.position="bottom") +
  labs(title = paste0("Principal components 1-&-2 using ",number_of_rep_meatbolites ," representative features"),
       subtitle  = paste0(" - Outliers are those ", VAR_PC_outlier_SD , " SD from the mean of PCs 1 to ", accelerationfactor ))
##

gridExtra::grid.arrange( grobs = list(ptable, pcplot), widths = c(2, 3), ncol = 2) 

```

# 3. Summary: filtered data

Relative to the raw data, `r nrow(raw_data$metabolite_data) - nrow(qc_data$metabolite_data)` samples were filtered out and `r ncol(raw_data$metabolite_data) - ncol(qc_data$metabolite_data)` features were filtered out.

```{r table-filtered-samplesize, fig.height=2}
tout = data.frame("data.set" = c("number of samples","number of features"),  
                  "raw.data" = dim(raw_data$metabolite_data),
                  "filtered.data" = dim(qc_data$metabolite_data))
ggpubr::ggtexttable(tout, rows = NULL, theme = ggpubr::ttheme("mBlue"))
```

## Missingness
```{r plot-combined-missingness, fig.width = 20, fig.height = 12, echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, dev = "png", fig.cap="Feature missingness across samples for the raw (left) and filtered (right) data"}

# Prepare Raw data
namat_raw = raw_data$metabolite_data
namat_raw[!is.na(namat_raw)] = 1
namat_raw[is.na(namat_raw)] = 0
namat_raw = as.matrix(namat_raw)
namat_raw = reshape::melt(namat_raw)
colnames(namat_raw) = c("individuals","features","missingness")
namat_raw$type = "raw"

# Prepare QC data
namat_qc = qc_data$metabolite_data
namat_qc[!is.na(namat_qc)] = 1
namat_qc[is.na(namat_qc)] = 0
namat_qc = as.matrix(namat_qc)
namat_qc = reshape::melt(namat_qc)
colnames(namat_qc) = c("individuals","features","missingness")
namat_qc$type = "filtered"

# Combine the two datasets
combined_data = rbind(namat_raw, namat_qc)

# Define color palette
pcol = RColorBrewer::brewer.pal(n = 8, name = 'Dark2')

# Create the plot
combined_data$type <- factor(combined_data$type, levels = c("raw", "qc"))
ggplot(combined_data, aes(features, individuals, fill = missingness)) + 
  geom_tile() + 
  scale_fill_gradient(low = "white", high = pcol[5]) +
  facet_wrap(~ type) +  # Change to "free_x" to have separate x-axes
  theme_cowplot() +
  theme(legend.position = "none",  # Remove legend
        axis.text.x = element_blank(), # Remove x-axis tick labels
        axis.ticks.x = element_blank(),
        text = element_text(size = 40)) +
  ylab("samples") +
  xlab("features")
```

```{r plot-filtered-missingness, fig.cap="Figure A: Distribution of sample missingness with sample mean illustrated by the red vertical line; Figure B: Distribution of feature missingness with sample mean illustrated by the red vertical line; Figure C: Table of sample and feature missingness percentiles (i.e., a table of Figure A B); Figure D: Estimates of study samples sizes under various levels of feature missingness."}
# missingness plots ====
r_mis = missingness.sum(mydata = qc_data$metabolite_data)
ggpubr::ggarrange(r_mis[[4]][[1]],
                  r_mis[[4]][[2]], 
                  r_mis[[4]][[3]],
                  r_mis[[4]][[4]],
                  ncol = 2, nrow = 2,
                  labels = c("a", "b", "c", "d") )
```

```{r plot-filtered-tpa, fig.cap="Total peak abundance histogram shows the total peak abundance for samples (y) across features (x) with the mean total peak abundance highlighted by the red veritcal line"}
# total peak area plot ====
s = tibble::tibble(TPA_completefeature = qc_data$sample_data$TPA_completefeature)
qc_data$sample_data %>% 
  ggplot( aes( TPA_completefeature ) ) +
    geom_histogram( fill = pcol[2] , bins = 25) + 
    geom_vline( xintercept = median(qc_data$sample_data$TPA_completefeature), color = pcol[1], size = 1) +
    labs(title = paste0("total peak area of samples (complete features)"), x="total peak area", y="count") +
    theme_cowplot() + 
    theme(plot.title = element_text(hjust = 0.5))
```

## Clusters & variance
```{r plot-filtered-dendrogram, fig.cap="Spearman's correlation distance clustering dendrogram highlighting the features used as representative features in blue, the clustering tree cut height is denoted by the horizontal line."}
# dendrogram ====
dend = qc_data$feature_tree %>% as.dendrogram

## create a vector of colors to color your tree labels
w = which( qc_data$feature_data$independent_features_binary == 1)
pv_ids = as.character( unlist( qc_data$feature_data[w,1] ) )
n = labels(dend)
bcol = rep("black", length(n))
w = which(n %in% pv_ids ); bcol[w] = pcol[2]

## redefine elements of dendrogram
dend = dend %>% 
  set("labels_cex", 0.5) %>% 
  set("labels_col", bcol) %>% 
  set("branches_lwd", 0.5) %>%
  set("branches_k_color",  value = bcol)
dend <- as.ggdend(dend)
## plot the dendrogram
dend %>% 
  ggplot() + 
  geom_hline(yintercept = VAR_tree_cut_height, color = "coral2")

```

```{r plot-filtered-scree-pc, fig.cap="Scree plot of the variance explained by each PC (left) and scatter plot of PC1 and PC2 as derived from the representative features (right)."}
pcol = RColorBrewer::brewer.pal(9, "Set1")

# scree plot ====
ve = tibble::tibble( data.frame(PC= 1:length(qc_data$varexp), VarExp = qc_data$varexp) )
screeplot = ve %>% ggplot(aes(x = PC, y = VarExp)) +
  geom_line(color = "grey") +
  geom_point(shape = 21, fill = pcol[2], size = 2) +
  labs(title = "Scree plot") +
  geom_vline(xintercept = qc_data$accelerationfactor, color = pcol[1]) +
  geom_vline(xintercept = unlist( qc_data$nparallel ), color = pcol[3]) +
  theme_cowplot()

# pc plot ====
pcs = as_tibble(qc_data$sample_data[, c("PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8","PC9","PC10")])
pcs$cluster_k = as.factor( kmeans(pcs[, 1:2], 4)$cluster )
## define color scheme
pcol = RColorBrewer::brewer.pal(9, "Set1")
##
pcplot = pcs %>% ggplot( aes(x = PC1, y = PC2) ) +
  geom_point( size = 2.5, shape = 21, aes(fill = cluster_k) ) +
  scale_fill_manual(values = pcol[1:4]) +
  labs( title = paste0("Representative features: ", number_of_rep_meatbolites),
        x = paste0("PC1  VarExp = ", signif(qc_data$varexp[1], d = 4)*100, "%" ),
        y = paste0("PC2  VarExp = ", signif(qc_data$varexp[2], d = 4)*100 , "%"),
        fill = paste0("kmeans\ncluster")) +
  theme_cowplot()

# arrange
plot_grid(screeplot, pcplot)
```
The Scree plot also identifies the number of PCs estimated to be informative (vertical lines) by the Cattel's Scree Test acceleration factor (red, n = `r qc_data$accelerationfactor`) and Parallel Analysis (green, n = `r unlist(qc_data$nparallel)`). Individuals in the PC plot were clustered into 4 kmeans (k) clusters, using data from PC1 and PC2. The kmeans clustering and color coding is strictly there to help provide some visualization of the major axes of variation in the sample population(s).

<!---
# data reduction table ====
feature_count = length(qc_data$feature_data$k)
features_included_in_data_reduction = length(na.omit(qc_data$feature_data$k) )
cluster_count = length( unique( na.omit(qc_data$feature_data$k) ) )
number_of_rep_meatbolites = sum( qc_data$feature_data$independent_features_binary == 1 )

temp = data.frame( data.reduction = c("feature count",
                                      "features included in data reduction",
                                      "number of features clusters",
                                      "number of representative features"),
                   count = c(feature_count, 
                             features_included_in_data_reduction, 
                             cluster_count, 
                             number_of_rep_meatbolites  ) )
ptable = ggpubr::ggtexttable( temp, rows = NULL, theme = ggpubr::ttheme("mBlue"))--->

## Structure
```{r plot-filtered-PCs, fig.height=8, fig.width=8, fig.cap="A matrix (pairs) plot of the top five principal components including demarcations of the 3rd (grey), 4th (orange), and 5th (red) standard deviations from the mean. Samples are color coded as in the summary PC plot above using a kmeans analysis of PC1 and PC2 with a k (number of clusters) set at 4. The choice of k = 4 was not robustly chosen it was a choice of simplicity to help aid visualize variation and sample mobility across the PCs."}
plotcolors = pcol[pcs$cluster_k]
pcapairs_bymoose(as.matrix(pcs[, 1:5]), varexp = qc_data$varexp, pcol = plotcolors)
```

## Estimates of normality
```{r data-wstat}
wstat = qc_data$feature_data$W
## how many stats were estimated
count = length(wstat)
nacount = sum(is.na(wstat))
remain_count = count - nacount
normcount = sum(wstat >= 0.95, na.rm = TRUE)

# log
W = wstat
pcol = RColorBrewer::brewer.pal(9, "Set1")
W_log10 = qc_data$feature_data$log10_W
LogMakesDistributionWorse = c( sum( W_log10 < W , na.rm = TRUE), signif( sum( W_log10 < W , na.rm = TRUE)/length(!is.na(W) ), d = 3)*100)
normcount_log = sum(W_log10 >= 0.95, na.rm = TRUE)


```

```{r plot-combined-shapirow, fig.cap="Histogram plots of Shapiro W-statistics for filtered (left) and filtered log transformed (right) data distributions. "}
par(mfrow = c(1,2), oma = c(2,1,1,1))

hist(W, breaks = 50, 
     col = pcol[2], 
     main = paste("Un-transformed data"), 
     xlab = "W", 
     ylab = "Frequency",
     cex.main = 0.75)
abline(v = 0.95, col = pcol[1])

hist(W_log10, breaks = 50, 
     col = pcol[3], 
     main = paste("Log10 transformed data"), 
     xlab = "W", 
     ylab = "Frequency",
     cex.main = 0.75)
abline(v = 0.95, col = pcol[1])

```

A W-statistic of 1 indicates the sample distribution is perfectly normal. A W-statistic of 0 indicates the sample distribution is perfectly uniform. Of the `r count` features in the data, `r nacount` features were excluded from this analysis because of no variation or too few observations (n < 40). Of the `r remain_count` features included, a total of `r normcount` may be considered normally distributed given a Shapiro W-statistic >= 0.95. After log transformation, `r normcount_log` may be considered normally distributed given a Shapiro W-statistic >= 0.95. Note: after log transformation, `r LogMakesDistributionWorse[1]` features have W-statistics that are < if they were not log transformed. 

## Outliers

Evaluation of the number of samples and features that are outliers across the data. There may be extreme outlying observations at individual features that have not been accounted for. You may want to:

1. Turn these observations into NAs.
2. Winsorize the data to some maximum value.
3. Rank normalize the data which will place those outliers into the top of the ranked standard normal distribution.
4. Turn these observations into NAs and then impute them along with other missing data in your data set. 

The table reports the average number of outlier values for samples and features in the data set. The minimum, max and other quantiles of the sample and feature distributions are reported as well.

```{r table-filtered-outliers, echo = FALSE, fig.width = 8, fig.height = 2.5, warning=FALSE, message=FALSE, error=FALSE}
Omat = outlier.matrix(qc_data$metabolite_data)
Total_Out_Count = sum(Omat)
sout = apply(Omat, 1, function(x){ sum(x, na.rm = TRUE)  })
fout = apply(Omat, 2, function(x){ sum(x, na.rm = TRUE)  })
sam_out_quantiles = c( quantile(sout, probs = c(0, 0.25, 0.5), na.rm = TRUE), 
                       signif( mean(sout, na.rm = TRUE), digits = 4 ), 
                       quantile(sout, probs = c( 0.75, 1), na.rm = TRUE) )
feat_out_quantiles = c( quantile(fout, probs = c(0, 0.25,0.5), na.rm = TRUE), 
                       signif( mean(fout, na.rm = TRUE), digits = 4 ) , 
                       quantile(fout, probs = c(  0.75, 1), na.rm = TRUE) )
outvals = data.frame(quantile = c("minimum", "25th" ,"median", "mean" ,"75th","max"), samples = sam_out_quantiles, features = feat_out_quantiles )
ggpubr::ggtexttable( outvals, rows = NULL, theme = ggpubr::ttheme("mBlue"))
```

# 4. Variation in filtered data by available variables

### Feature missingness
Feature missingness may be influenced by biology or pathway classification, or your technologies methodology. The figure(s) below provide an illustrative evaluation of the proportion of *feature missigness* as a product of the variable(s) available in the raw data files (e.g., batch). 

```{r data-filtered-feature-batchvars}
## what are all of the variables that could be used to evaluate feature effects?
possible_vars = colnames(qc_data$feature_data)
## remove summary stats from pool of possible
w = which(possible_vars == "feature_missingness")
if(length(w) == 1){
  possible_vars = possible_vars[ -c(w:length(possible_vars)) ]  
}

## number of unique units for each possible variable?
count_unique = apply(qc_data$feature_data[,possible_vars], 2, function(x){  length( unique( na.omit(x) ) )  })

## remove those with only one class or count == sample size
r = which(count_unique == 1 | count_unique == nrow(qc_data$feature_data) | count_unique > 96)
if(length(r) > 0){
  possible_vars = possible_vars[-r]
  count_unique = count_unique[-r]
}

## continue filtering
if( length(possible_vars) > 0){
  ## estimate min, mean, max number of values within a variable
  features_per_unit = t( apply( qc_data$feature_data[,possible_vars], 2, function(x){  
    x = table( unlist(x) )
    out = c( min(x), median(x), max(x) ); names(out) = c("min","median","max")
    out
  }) )
  features_per_unit = as.data.frame( cbind( count_unique, features_per_unit) )
  ## filter 2 class min of 1 variables
  r = which(features_per_unit$count_unique == 2 & features_per_unit$min == 1)
  if(length(r) > 0){ features_per_unit = features_per_unit[-r,] }
  
  ## filter for median observational count
  k = which(features_per_unit$median >= 5 )
  possible_vars = possible_vars[k]
}
## define
class_variables = possible_vars
if(length(class_variables)==0){
  paste0(" -- No feature level batch variables identified or all were invariable -- ") 
}
```

```{r plot-filtered-feature-batchvars, fig.cap="Box plot illustration(s) of the relationship that feature variables have with feature missingness."}
# MISSINGNESS
if(length(class_variables) > 0 & length(class_variables)<=2){
  ClassMisPlots = lapply( class_variables , function(x){
  out = variable.by.factor( dep = qc_data$feature_data$feature_missingness , 
                           indep = unlist( qc_data$feature_data[,x] ), 
                           dep_name = "feature missingness", 
                           indep_name = x, orderfactor = TRUE, violin = FALSE )
  return(out)
  })
  ## plot the output
  gridExtra::grid.arrange( grobs = ClassMisPlots, ncol = 1)
}

if(length(class_variables)>2){
  ClassMisPlots = lapply( class_variables , function(x){
  out = variable.by.factor( dep = qc_data$feature_data$feature_missingness ,
                           indep = unlist( qc_data$feature_data[,x] ), 
                           dep_name = "feature missingness", 
                           indep_name = x, orderfactor = TRUE, violin = FALSE )
  return(out)
  })
  ## plot the output
  gridExtra::grid.arrange( grobs = ClassMisPlots, ncol = 1)

}
```

### Sample missingness
Sample missingness may be influenced by methodology, both of the study design and of measurement. The figure(s) below provide an illustrative evaluation of the proportion of *sample missigness* as a product of sample variable(s) provided by your supplier. This is the univariate influence of batch effects on *sample missingness*.

```{r data-filtered-sample-batchvars}
# identify vars ====
## what are all of the variables that could be used to evaluate feature effects?
possible_vars = colnames(qc_data$sample_data)

## remove summary stats from pool of possible
w = which(possible_vars == "sample_missingness")
if(length(w)>0){
  possible_vars = possible_vars[ -c(w:length(possible_vars)) ]  
}

if(length(possible_vars)>0){
  cat( paste0(" -- A total of ",length(possible_vars)," possible feature level batch variables were identified in the sample data table. -- \n") )
}

## number of unique units for each possible variable?
count_unique = apply(qc_data$sample_data[,possible_vars], 2, function(x){  length( unique( na.omit(x) ) )  })

## remove those with only one class or count == sample size
r = which(count_unique <= 1 | count_unique == nrow(qc_data$sample_data) | count_unique > 96)
if(length(r) > 0){
  possible_vars = possible_vars[-r]
  count_unique = count_unique[-r]
}

## continue filtering
if( length(possible_vars) > 0){
  ## estimate min, mean, max number of values within a variable
  features_per_unit = t( apply( qc_data$sample_data[,possible_vars], 2, function(x){  
    x = table( unlist(x) )
    out = c( min(x), median(x), max(x) ); names(out) = c("min","median","max")
    out
  }) )
  features_per_unit = as.data.frame( cbind( count_unique, features_per_unit) )
  ## filter 2 class min of 1 variables
  # r = which(features_per_unit$count_unique == 2 & features_per_unit$min == 1)
  r = which(features_per_unit$count_unique < 2 | features_per_unit$min < 10)
  if(length(r) > 0){ features_per_unit = features_per_unit[-r,] }
  
  ## filter for median observational count
  k = which(features_per_unit$median >= 5 )
  possible_vars = possible_vars[k]
}

## define
batch_variables = possible_vars

if(length(batch_variables)==0){
  cat( paste0(" -- No feature level batch variables identified or all were invariable -- \n") )
}

if(length(batch_variables)>0){
  cat( paste0(" -- After filtering a total of ",length(batch_variables)," feature level batch variables were identified. -- \n") )
}

if(length(batch_variables)>0){
  cat( paste0(" -- They are:\n") )
  cat( paste0("\t", batch_variables, "\n") )
}

# FORMAT THE BATCH COVARIABLES ====
## Turn any NAs in the batch variables into a "string"
if(length(batch_variables)>0){
  ## extract the batch covariables
  covars = as.data.frame( qc_data$sample_data[ , batch_variables ] )
  
  ## account for NAs
  for(i in 1:ncol(covars)){ 
    w = which(is.na(covars[,i] ))
    if(length(w)>0){
      covars[w,i] = "NA_other" 
      }
  }
  ## convert to factors
  for(i in 1:ncol(covars)){ covars[,i] = as.factor(as.character(covars[,i])) }
  
  ## replace batch variable in qc_data$sample_data
  qc_data$sample_data[ , batch_variables ] = covars
}

# TEST FOR BATCH COVARIABLE REDUNDANCIES ====
if(length(batch_variables)>1){
  Cmat = matrix(0, length(batch_variables), length(batch_variables), dimnames = list(batch_variables,batch_variables))
  ##
  for(i in batch_variables ){
    for(j in batch_variables ){
      mat = table( unlist( qc_data$sample_data[ , i ] ) , unlist( qc_data$sample_data[ , j ] ) )
      cv = cramerV(mat)
      Cmat[i,j] = cv
    }
  }
  ## distance matrix
  Dmat = as.dist(1-Cmat)
  ## dendrogram
  nj = hclust(Dmat, method = "complete")
  ## tree cut for clusters Cramer's V > 0.95
  k = cutree(nj, h = 0.05)
  ## extract unique batch variables
  new_batch_variables = c()
  for(i in unique(k)){
      w = which(k == i)
      new_batch_variables = c(new_batch_variables, batch_variables[ w[1] ])
  }
  ## Redefine batch variables
  batch_variables = new_batch_variables
  
  cat( paste0(" -- After testing for redundancies a total of ", length(batch_variables)," feature level batch variables remain. -- \n") )
  
  cat( paste0(" -- They are:\n") )
  cat( paste0("\t", batch_variables, "\n") )
  
}
```

```{r plot-filtered-sample-batchvars, fig.cap="Box plot illustration(s) of the relationship that available batch variables have with sample missingness."}
## MISSINGNESS
# 1 variable
if( length(batch_variables) > 0 & length(batch_variables) <= 2 ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = qc_data$sample_data$sample_missingness , 
                              indep = unlist( qc_data$sample_data[,x] ), 
                              dep_name = "sample missingness", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 1)
} 

# 2-4 variables
if( length(batch_variables) > 2 & length(batch_variables) <= 4 ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = qc_data$sample_data$sample_missingness , 
                              indep = unlist( qc_data$sample_data[,x] ), 
                              dep_name = "sample missingness", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 1)
}

# >4 variables
if( length(batch_variables) > 4 ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = qc_data$sample_data$sample_missingness, 
                              indep = unlist( qc_data$sample_data[,x] ), 
                              dep_name = "sample missingness", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 2)
} 
```

## Multivariate evaluation: batch variables
```{r data-filtered-sample-multivatiaveANOVA, fig.cap="Type2 ANOVA: the eta-squared (eta-sq) estimates are an estimation of the percent of variation explained by each independent variable, after accounting for all other variables, as derived from the sum of squares. This is a multivariate evaluation of batch variables on *sample missingness*. Presence of NA's would indicate that the model is inappropriate."}
if( length(batch_variables) > 0 ) {
  covars = as.data.frame( qc_data$sample_data[ , batch_variables ] )
  ## run multivariate ANOVA
  ( multivariate.anova(dep = qc_data$sample_data$sample_missingness, indep_df = covars ) )
} else {
  paste0(" -- No sample level batch variables were provided or all were invariable -- ")
  }
```

# 5. Total peak area of samples:
The total peak area (TPA) is the sum of the abundances measured across all features for a sample. TPA is one measure that can be used to identify unusual samples given their entire profile. However, the level of missingness in a sample may influence TPA. To account for this we:  

1. Evaluate the correlation between TPA across all features with TPA measured using only those features with complete data (no missingness)
2. Determine if the batch effects have a measurable impact on TPA

```{r plot-filtered-tpa-missingness, fig.width=6, fig.height=6, fig.cap="Correlation between total peak area and missingness using complete case"}
a = cor.test(x = qc_data$sample_data$sample_missingness, y = qc_data$sample_data$TPA_completefeature, method = "spearman")
###
( 
  tpamis = qc_data$sample_data %>% ggplot( aes(x = TPA_completefeature, y = sample_missingness)) +
  geom_point( fill = "grey", alpha = 0.8, size = 1.5) + 
  geom_smooth(method = "loess", color = "red", size = 2)  +
  geom_smooth(method = "lm", color = "blue", size = 2)  +
  labs(x = "total peak area", y = "sample missingness",
       title = paste0( "Spearmans's cor = ", round(a$estimate, d = 4))) +
    theme_cowplot()
  )
```

## Univariate evaluation: batch effects
The figure(s) below provide an illustrative evaluation of the  *total peak area* (at complete features) as a product of sample batch variables provided by your supplier. 

```{r data-filtered-tpa-batch}
if(length(batch_variables) == 0 ) { 
  paste0(" -- No sample level batch variables were provided or all were invariable -- ") 
}
```

```{r plot-filtered-tpa-batch, fig.cap="Violin plot of the relationship between total peak area and sample batch variables that are available in your data using complete case."}
# 1 varaible 
if( length(batch_variables) > 0 & length(batch_variables) <= 2 ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = qc_data$sample_data$TPA_completefeature, 
                              indep = unlist( qc_data$sample_data[,x] ), 
                              dep_name = "total peak area", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 1)
}

# 2-4 variables
if( length(batch_variables) > 2 & length(batch_variables) <= 4 ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = qc_data$sample_data$TPA_completefeature, 
                              indep = unlist( qc_data$sample_data[,x] ), 
                              dep_name = "total peak area", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 1)
}

# >4 variables
if( length(batch_variables) > 4 ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = qc_data$sample_data$TPA_completefeature, 
                              indep = unlist( qc_data$sample_data[,x] ), 
                              dep_name = "total abundance", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 2)
}
```

## Multivariate evaluation: batch variables
```{r plot-filtered-tpa-batch-multivariateANNOVA, fig.cap="Type2 ANOVA: the eta-squared (eta-sq) estimates are an estimation on the percent of variation explained by each independent variable, after accounting for all other variables, as derived from the sum of squares. This is a multivariate evaluation of batch variables on *total peak area* at complete features."}
if( length(batch_variables)>0 ) {
  ( multivariate.anova(dep = qc_data$sample_data$TPA_completefeature, 
                                indep_df = qc_data$sample_data[,batch_variables ] ) ) 
}else {
  paste0(" -- No sample level batch variables were provided or all were invariable -- ")
  }
```

# 6. Power analysis

The below plots are an exploration for case/control and continuous outcome data using the filtered data set. Analytical power analysis for both continuous and imbalanced presence/absence correlation analysis.

```{r power_exploration,fig.cap="Simulated effect sizes (standardized by trait SD) are illustrated by their color in each figure. Figure (A) provides estimates of power for continuous traits with the total sample size on the x-axis and the estimated power on the y-axis. Figure (B) provides estimates of power for presence/absence (or binary) traits in an imbalanced design. The estimated power is on the y-axis."}
# power calculations ====
p1 = run.cont.power.make.plot( mydata = qc_data$metabolite_data ) 
p2 = run.pa.imbalanced.power.make.plot(  mydata = qc_data$metabolite_data )

# plot ====
ggpubr::ggarrange(p1, p2, labels = c("A", "B"), ncol = 2, nrow = 1)
```

The total sample size is set to `r nrow(qc_data$metabolite_data)` and the x-axis depicts the number of individuals present (or absent) for the trait. The effects sizes illustrated here were chosen by running an initial set of simulations which identified effects sizes that would span a broad range of power estimates given the sample population's sample size.
